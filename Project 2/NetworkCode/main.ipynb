{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96b5b95c",
   "metadata": {},
   "source": [
    "# 准备工作\n",
    "\n",
    "## 导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os.path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc03830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import *\n",
    "from vgg import VGG, VGG_BN\n",
    "from load import load\n",
    "from util import set_random_seeds, get_num_parameters, train, train_plus\n",
    "from visual import loss_landscape, grad_pred, beta_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bde3ad1",
   "metadata": {},
   "source": [
    "## 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "set_random_seeds(seed = 0, device = device)\n",
    "\n",
    "train_loader = load(train = True)\n",
    "test_loader = load(train = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "26aafe5b",
   "metadata": {},
   "source": [
    "# 神经网络\n",
    "\n",
    "## 初始架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8310760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\tTrain Error: 0.46426\tTest Error: 0.46610\n",
      "Epoch:  2\tTrain Error: 0.39284\tTest Error: 0.40720\n",
      "Epoch:  3\tTrain Error: 0.34746\tTest Error: 0.37080\n",
      "Epoch:  4\tTrain Error: 0.30776\tTest Error: 0.34930\n",
      "Epoch:  5\tTrain Error: 0.29376\tTest Error: 0.35000\n",
      "Epoch:  6\tTrain Error: 0.26306\tTest Error: 0.33230\n",
      "Epoch:  7\tTrain Error: 0.22036\tTest Error: 0.30660\n",
      "Epoch:  8\tTrain Error: 0.20134\tTest Error: 0.30160\n",
      "Epoch:  9\tTrain Error: 0.19084\tTest Error: 0.30770\n",
      "Epoch: 10\tTrain Error: 0.16584\tTest Error: 0.30770\n",
      "Epoch: 11\tTrain Error: 0.15242\tTest Error: 0.30270\n",
      "Epoch: 12\tTrain Error: 0.13310\tTest Error: 0.30720\n",
      "Epoch: 13\tTrain Error: 0.12722\tTest Error: 0.31080\n",
      "Epoch: 14\tTrain Error: 0.10172\tTest Error: 0.30940\n",
      "Epoch: 15\tTrain Error: 0.09734\tTest Error: 0.30760\n",
      "Epoch: 16\tTrain Error: 0.09870\tTest Error: 0.31590\n",
      "Epoch: 17\tTrain Error: 0.06678\tTest Error: 0.31460\n",
      "Epoch: 18\tTrain Error: 0.05868\tTest Error: 0.31480\n",
      "Epoch: 19\tTrain Error: 0.05860\tTest Error: 0.32420\n",
      "Epoch: 20\tTrain Error: 0.06242\tTest Error: 0.32970\n"
     ]
    }
   ],
   "source": [
    "model = NN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "root = '../Result/NN original 0.001'\n",
    "best_model_file = os.path.join(root, 'model.pt')\n",
    "losses_file = os.path.join(root, 'losses.pt')\n",
    "train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "_, train_errors_original, test_errors_original = \\\n",
    "    train(model, optimizer, criterion, train_loader, test_loader, device = device, \n",
    "          wrap_tqdms = False, print_errors = True,\n",
    "          best_model_file = best_model_file, losses_file = losses_file,\n",
    "          train_errors_file = train_errors_file, test_errors_file = test_errors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e0ae15",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", get_num_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "root = '../Result/NN original'\n",
    "losses_file = os.path.join(root, 'losses.pt')\n",
    "train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "losses_original = torch.load(losses_file)\n",
    "train_errors_original = torch.load(train_errors_file)\n",
    "test_errors_original = torch.load(test_errors_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d385545",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_errors_original, '-+')\n",
    "plt.plot(test_errors_original, '-+')\n",
    "plt.xticks(range(0, 21, 2))\n",
    "plt.legend(['train', 'test'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.title('error on training and testing set')\n",
    "\n",
    "fig_file = os.path.join(root, 'figure.png')\n",
    "plt.savefig(fig_file)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebddfd3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr = [1e-3, 2e-3, 1e-4, 5e-4]\n",
    "losses_original = [losses_original, [], [], []]\n",
    "for ind in range(1, 4):\n",
    "    model = NN()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr[ind])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    root = '../Result/NN original ' + str(lr[ind])\n",
    "    best_model_file = os.path.join(root, 'model.pt')\n",
    "    losses_file = os.path.join(root, 'losses.pt')\n",
    "    train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "    test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "    print('lr =', lr[ind])\n",
    "    losses_original[ind], _, _ = \\\n",
    "        train(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "              wrap_tqdms = False, print_errors = True,\n",
    "              best_model_file = best_model_file, losses_file = losses_file,\n",
    "              train_errors_file = train_errors_file, test_errors_file = test_errors_file)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses_original = []\n",
    "for ind in range(4):\n",
    "    root = '../Result/NN original ' + str(lr[ind])\n",
    "    losses_file = os.path.join(root, 'losses.pt')\n",
    "\n",
    "    losses_original.append(torch.load(losses_file))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "310cdf89",
   "metadata": {},
   "source": [
    "## 神经元数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c50ed1e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = NN(hidden_channels = (4, 8), hidden_neurons = (32, 32))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "root = '../Result/NN smaller'\n",
    "best_model_file = os.path.join(root, 'model.pt')\n",
    "losses_file = os.path.join(root, 'losses.pt')\n",
    "train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "_, train_errors_smaller, test_errors_smaller = \\\n",
    "    train(model, optimizer, criterion, train_loader, test_loader, device = device, \n",
    "          wrap_tqdms = False, print_errors = True,\n",
    "          best_model_file = best_model_file, losses_file = losses_file,\n",
    "          train_errors_file = train_errors_file, test_errors_file = test_errors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e5c23a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", get_num_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1060bf46",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = NN(hidden_channels = (64, 128), hidden_neurons = (512, 512))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "root = '../Result/NN bigger'\n",
    "best_model_file = os.path.join(root, 'model.pt')\n",
    "losses_file = os.path.join(root, 'losses.pt')\n",
    "train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "_, train_errors_bigger, test_errors_bigger = \\\n",
    "    train(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "          wrap_tqdms = False, print_errors = True,\n",
    "          best_model_file = best_model_file, losses_file = losses_file,\n",
    "          train_errors_file = train_errors_file, test_errors_file = test_errors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837eb85d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", get_num_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6b6eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_errors_original, '-+')\n",
    "plt.plot(train_errors_smaller, '-+')\n",
    "plt.plot(train_errors_bigger, '-+')\n",
    "plt.xticks(range(0, 21, 2))\n",
    "plt.legend(['original', 'smaller', 'bigger'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.title('error with different network structures')\n",
    "\n",
    "fig_file = os.path.join(root, 'figure.png')\n",
    "plt.savefig(fig_file)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa4eb9f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c033c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = NN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.MultiMarginLoss()\n",
    "\n",
    "root = '../Result/NN hinge'\n",
    "best_model_file = os.path.join(root, 'model.pt')\n",
    "losses_file = os.path.join(root, 'losses.pt')\n",
    "train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "_, train_errors_hinge, test_errors_hinge = \\\n",
    "    train(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "          wrap_tqdms = False, print_errors = True,\n",
    "          best_model_file = best_model_file, losses_file = losses_file,\n",
    "          train_errors_file = train_errors_file, test_errors_file = test_errors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c695f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_errors_original, '-+')\n",
    "plt.plot(train_errors_hinge, '-+')\n",
    "plt.xticks(range(0, 21, 2))\n",
    "plt.legend(['cross entropy', 'multi-class hinge'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.title('error with different loss functions')\n",
    "\n",
    "fig_file = os.path.join(root, 'figure.png')\n",
    "plt.savefig(fig_file)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b936bde",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b0083a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "weight_decay = (0.05, 0.01, 0.005, 0.0005, 5e-05, 5e-06)\n",
    "train_errors_regularize = [[], [], [], [], [], []]\n",
    "test_errors_regularize = [[], [], [], [], [], []]\n",
    "for ind in range(6):\n",
    "    model = NN()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay = weight_decay[ind])\n",
    "    criterion = nn.MultiMarginLoss()\n",
    "\n",
    "    root = '../Result/NN regularize ' + str(weight_decay[ind])\n",
    "    best_model_file = os.path.join(root, 'model.pt')\n",
    "    losses_file = os.path.join(root, 'losses.pt')\n",
    "    train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "    test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "    print('lambda =', weight_decay[ind])\n",
    "    _, train_errors_regularize[ind], test_errors_regularize[ind] = \\\n",
    "        train(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "              wrap_tqdms = False, print_errors = True,\n",
    "              best_model_file = best_model_file, losses_file = losses_file,\n",
    "              train_errors_file = train_errors_file, test_errors_file = test_errors_file)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9807c816",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for ind in range(6):\n",
    "    root = '../Result/NN regularize ' + str(weight_decay[ind])\n",
    "    train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "    test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "    train_errors_regularize[ind] = torch.load(train_errors_file)\n",
    "    test_errors_regularize[ind] = torch.load(test_errors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3423dc96",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_errors_original, '-+')\n",
    "for ind in range(6):\n",
    "    plt.plot(train_errors_regularize[ind], '-+')\n",
    "plt.xticks(range(0, 21, 2))\n",
    "plt.legend(['lambda = 0', 'lambda = 0.05', 'lambda = 0.01', 'lambda = 0.005',\n",
    "            'lambda = 0.0005', 'lambda = 5e-05', 'lambda = 5e-06'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.title('error with different regularization parameters')\n",
    "\n",
    "fig_file = os.path.join(root, 'figure.png')\n",
    "plt.savefig(fig_file)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f39b31",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a1b78c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = NN_tanh()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "root = '../Result/NN tanh'\n",
    "best_model_file = os.path.join(root, 'model.pt')\n",
    "losses_file = os.path.join(root, 'losses.pt')\n",
    "train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "_, train_errors_tanh, test_errors_tanh = \\\n",
    "    train(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "          wrap_tqdms = False, print_errors = True,\n",
    "          best_model_file = best_model_file, losses_file = losses_file,\n",
    "          train_errors_file = train_errors_file, test_errors_file = test_errors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c6a08",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = NN_softplus()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "root = '../Result/NN softplus'\n",
    "best_model_file = os.path.join(root, 'model.pt')\n",
    "losses_file = os.path.join(root, 'losses.pt')\n",
    "train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "_, train_errors_softplus, test_errors_softplus = \\\n",
    "    train(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "          wrap_tqdms = False, print_errors = True,\n",
    "          best_model_file = best_model_file, losses_file = losses_file,\n",
    "          train_errors_file = train_errors_file, test_errors_file = test_errors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804a10d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_errors_original, '-+')\n",
    "plt.plot(train_errors_tanh, '-+')\n",
    "plt.plot(train_errors_softplus, '-+')\n",
    "plt.xticks(range(0, 21, 2))\n",
    "plt.legend(['ReLU', 'tanh', 'softmax'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.title('error with different activation functions')\n",
    "\n",
    "fig_file = os.path.join(root, 'figure.png')\n",
    "plt.savefig(fig_file)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b388061",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce79673",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = NN()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "root = '../Result/NN SGD'\n",
    "best_model_file = os.path.join(root, 'model.pt')\n",
    "losses_file = os.path.join(root, 'losses.pt')\n",
    "train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "_, train_errors_SGD, test_errors_SGD = \\\n",
    "    train(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "          wrap_tqdms = False, print_errors = True,\n",
    "          best_model_file = best_model_file, losses_file = losses_file,\n",
    "          train_errors_file = train_errors_file, test_errors_file = test_errors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bdc731",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = NN()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "root = '../Result/NN momentum'\n",
    "best_model_file = os.path.join(root, 'model.pt')\n",
    "losses_file = os.path.join(root, 'losses.pt')\n",
    "train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "_, train_errors_momentum, test_errors_momentum = \\\n",
    "    train(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "          wrap_tqdms = False, print_errors = True,\n",
    "          best_model_file = best_model_file, losses_file = losses_file,\n",
    "          train_errors_file = train_errors_file, test_errors_file = test_errors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d237fe7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = NN()\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr = 0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "root = '../Result/NN Adagrad'\n",
    "best_model_file = os.path.join(root, 'model.pt')\n",
    "losses_file = os.path.join(root, 'losses.pt')\n",
    "train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "_, train_errors_Adagrad, test_errors_Adagrad = \\\n",
    "    train(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "          wrap_tqdms = False, print_errors = True,\n",
    "          best_model_file = best_model_file, losses_file = losses_file,\n",
    "          train_errors_file = train_errors_file, test_errors_file = test_errors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736a11ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_errors_original, '-+')\n",
    "plt.plot(train_errors_SGD, '-+')\n",
    "plt.plot(train_errors_momentum, '-+')\n",
    "plt.plot(train_errors_Adagrad, '-+')\n",
    "plt.xticks(range(0, 21, 2))\n",
    "plt.legend(['Adam', 'SGD', 'SGD + momentum', 'Adagrad'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.title('error with different optimizers')\n",
    "\n",
    "fig_file = os.path.join(root, 'figure.png')\n",
    "plt.savefig(fig_file)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e069570b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 批归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f7974",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = NN_BN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "root = '../Result/NN BN 0.001'\n",
    "best_model_file = os.path.join(root, 'model.pt')\n",
    "losses_file = os.path.join(root, 'losses.pt')\n",
    "train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "_, train_errors_BN, test_errors_BN = \\\n",
    "    train(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "          wrap_tqdms = False, print_errors = True,\n",
    "          best_model_file = best_model_file, losses_file = losses_file,\n",
    "          train_errors_file = train_errors_file, test_errors_file = test_errors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcf8aae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "root = '../Result/NN BN'\n",
    "losses_file = os.path.join(root, 'losses.pt')\n",
    "train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "losses_BN = torch.load(losses_file)\n",
    "train_errors_BN = torch.load(train_errors_file)\n",
    "test_errors_BN = torch.load(test_errors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea85c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_errors_original, '-+')\n",
    "plt.plot(train_errors_BN, '-+')\n",
    "plt.xticks(range(0, 21, 2))\n",
    "plt.legend(['without BN', 'with BN'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.title('error with or without batch normalization')\n",
    "\n",
    "fig_file = os.path.join(root, 'figure.png')\n",
    "plt.savefig(fig_file)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9d5a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_errors_BN, '-+')\n",
    "plt.plot(test_errors_BN, '-+')\n",
    "plt.xticks(range(0, 21, 2))\n",
    "plt.legend(['train', 'test'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.title('error on training and testing set')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cf6704",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "losses_BN = [[], [], [], []]\n",
    "for ind in range(4):\n",
    "    model = NN_BN()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr[ind])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    root = '../Result/NN BN ' + str(lr[ind])\n",
    "    best_model_file = os.path.join(root, 'model.pt')\n",
    "    losses_file = os.path.join(root, 'losses.pt')\n",
    "    train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "    test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "    print('lr =', lr[ind])\n",
    "    losses_BN[ind], _, _ = \\\n",
    "        train(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "              wrap_tqdms = False, print_errors = True,\n",
    "              best_model_file = best_model_file, losses_file = losses_file,\n",
    "              train_errors_file = train_errors_file, test_errors_file = test_errors_file)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8130d93",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "losses_BN = []\n",
    "for ind in range(4):\n",
    "    root = '../Result/NN BN ' + str(lr[ind])\n",
    "    losses_file = os.path.join(root, 'losses.pt')\n",
    "\n",
    "    losses_BN.append(torch.load(losses_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972467c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "min_curve, max_curve = loss_landscape(losses_original)\n",
    "plt.fill_between(range(len(min_curve)), min_curve, max_curve, alpha = 0.5)\n",
    "\n",
    "min_curve, max_curve = loss_landscape(losses_BN)\n",
    "plt.fill_between(range(len(min_curve)), min_curve, max_curve, alpha = 0.5)\n",
    "\n",
    "plt.legend(['NN without BN', 'NN with BN'])\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss landscape')\n",
    "\n",
    "fig_file = os.path.join(root, 'figure.png')\n",
    "plt.savefig(fig_file)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5faf075",
   "metadata": {},
   "source": [
    "## 丢弃法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c303f4e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prob = (0.2, 0.5)\n",
    "train_errors_dropout = [[], []]\n",
    "test_errors_dropout = [[], []]\n",
    "for ind in range(2):\n",
    "    model = NN_dropout(prob = prob[ind])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    root = '../Result/NN dropout ' + str(prob[ind])\n",
    "    best_model_file = os.path.join(root, 'model.pt')\n",
    "    losses_file = os.path.join(root, 'losses.pt')\n",
    "    train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "    test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "    print('prob =', prob[ind])\n",
    "    _, train_errors_dropout[ind], test_errors_dropout[ind] = \\\n",
    "        train(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "              wrap_tqdms = False, print_errors = True,\n",
    "              best_model_file = best_model_file, losses_file = losses_file,\n",
    "              train_errors_file = train_errors_file, test_errors_file = test_errors_file)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e479a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_errors_original, '-+')\n",
    "plt.plot(train_errors_dropout[0], '-+')\n",
    "plt.plot(train_errors_dropout[1], '-+')\n",
    "plt.xticks(range(0, 21, 2))\n",
    "plt.legend(['prob = 0', 'prob = 0.2', 'prob = 0.5'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.title('error with or without dropout')\n",
    "\n",
    "fig_file = os.path.join(root, 'figure.png')\n",
    "plt.savefig(fig_file)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273c6967",
   "metadata": {},
   "source": [
    "## 最优设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37acadc6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = NN_BN(hidden_channels = (64, 128), hidden_neurons = (512, 512))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "root = '../Result/NN opt'\n",
    "best_model_file = os.path.join(root, 'model.pt')\n",
    "losses_file = os.path.join(root, 'losses.pt')\n",
    "train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "losses, train_errors_opt, test_errors_opt = \\\n",
    "    train(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "          wrap_tqdms = False, print_errors = True,\n",
    "          best_model_file = best_model_file, losses_file = losses_file,\n",
    "          train_errors_file = train_errors_file, test_errors_file = test_errors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b826367",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_errors_opt, '-+')\n",
    "plt.plot(test_errors_opt, '-+')\n",
    "plt.xticks(range(0, 21, 2))\n",
    "plt.legend(['train', 'test'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.title('error on training and testing set')\n",
    "\n",
    "fig_file = os.path.join(root, 'figure.png')\n",
    "plt.savefig(fig_file)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VGG网络"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses_original = [[], [], [], []]\n",
    "for ind in range(4):\n",
    "    model = VGG()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr[ind])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    root = '../Result/VGG original ' + str(lr[ind])\n",
    "    best_model_file = os.path.join(root, 'model.pt')\n",
    "    losses_file = os.path.join(root, 'losses.pt')\n",
    "    train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "    test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "    print('lr =', lr[ind])\n",
    "    losses_original[ind], _, _ = \\\n",
    "        train(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "              wrap_tqdms = True, print_errors = True,\n",
    "              best_model_file = best_model_file, losses_file = losses_file,\n",
    "              train_errors_file = train_errors_file, test_errors_file = test_errors_file)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses_original = []\n",
    "for ind in range(4):\n",
    "    root = '../Result/VGG original ' + str(lr[ind])\n",
    "    losses_file = os.path.join(root, 'losses.pt')\n",
    "\n",
    "    losses_original.append(torch.load(losses_file))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses_BN = [[], [], [], []]\n",
    "for ind in range(4):\n",
    "    model = VGG_BN()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr[ind])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    root = '../Result/VGG BN ' + str(lr[ind])\n",
    "    best_model_file = os.path.join(root, 'model.pt')\n",
    "    losses_file = os.path.join(root, 'losses.pt')\n",
    "    train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "    test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "    print('lr =', lr[ind])\n",
    "    losses_BN[ind], _, _ = \\\n",
    "        train(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "              wrap_tqdms = True, print_errors = True,\n",
    "              best_model_file = best_model_file, losses_file = losses_file,\n",
    "              train_errors_file = train_errors_file, test_errors_file = test_errors_file)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses_BN = []\n",
    "for ind in range(4):\n",
    "    root = '../Result/VGG BN ' + str(lr[ind])\n",
    "    losses_file = os.path.join(root, 'losses.pt')\n",
    "\n",
    "    losses_BN.append(torch.load(losses_file))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min_curve, max_curve = loss_landscape(losses_original)\n",
    "plt.fill_between(range(len(min_curve)), min_curve, max_curve, alpha = 0.75)\n",
    "\n",
    "min_curve, max_curve = loss_landscape(losses_BN)\n",
    "plt.fill_between(range(len(min_curve)), min_curve, max_curve, alpha = 0.75)\n",
    "\n",
    "plt.legend(['VGG without BN', 'VGG with BN'])\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss landscape')\n",
    "\n",
    "fig_file = os.path.join(root, 'figure.png')\n",
    "plt.savefig(fig_file)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "root = '../Result/VGG original 0.001'\n",
    "train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "train_errors_original = torch.load(train_errors_file, map_location = device)\n",
    "\n",
    "root = '../Result/VGG BN 0.001'\n",
    "train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "train_errors_BN = torch.load(train_errors_file, map_location = device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(train_errors_original, '-+')\n",
    "plt.plot(train_errors_BN, '-+')\n",
    "plt.xticks(range(0, 21, 2))\n",
    "plt.legend(['without BN', 'with BN'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.title('error with or without batch normalization')\n",
    "\n",
    "fig_file = os.path.join(root, 'figure.png')\n",
    "plt.savefig(fig_file)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parameters_original = [[], [], [], []]\n",
    "grads_original = [[], [], [], []]\n",
    "for ind in range(4):\n",
    "    model = VGG()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr[ind])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    root = '../Result/VGG original ' + str(lr[ind])\n",
    "    best_model_file = os.path.join(root, 'model.pt')\n",
    "    parameters_file = os.path.join(root, 'parameters.pt')\n",
    "    grads_file = os.path.join(root, 'grads.pt')\n",
    "    train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "    test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "    print('lr =', lr[ind])\n",
    "    parameters_original[ind], grads_original[ind], _, _ = \\\n",
    "        train_plus(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "                   wrap_tqdms = True, print_errors = True,\n",
    "                   best_model_file = best_model_file,\n",
    "                   parameters_file = parameters_file, grads_file = grads_file,\n",
    "                   train_errors_file = train_errors_file, test_errors_file = test_errors_file)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parameters_original = []\n",
    "grads_original = []\n",
    "for ind in range(4):\n",
    "    root = '../Result/VGG original ' + str(lr[ind])\n",
    "    parameters_file = os.path.join(root, 'parameters.pt')\n",
    "    grads_file = os.path.join(root, 'grads.pt')\n",
    "\n",
    "    parameters_original.append(torch.load(parameters_file, map_location = device))\n",
    "    grads_original.append(torch.load(grads_file, map_location = device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parameters_BN = [[], [], [], []]\n",
    "grads_BN = [[], [], [], []]\n",
    "for ind in range(4):\n",
    "    model = VGG_BN()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr[ind])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    root = '../Result/VGG BN ' + str(lr[ind])\n",
    "    best_model_file = os.path.join(root, 'model.pt')\n",
    "    parameters_file = os.path.join(root, 'parameters.pt')\n",
    "    grads_file = os.path.join(root, 'grads.pt')\n",
    "    train_errors_file = os.path.join(root, 'train_errors.pt')\n",
    "    test_errors_file = os.path.join(root, 'test_errors.pt')\n",
    "\n",
    "    print('lr =', lr[ind])\n",
    "    parameters_BN[ind], grads_BN[ind], _, _ = \\\n",
    "        train_plus(model, optimizer, criterion, train_loader, test_loader, device = device,\n",
    "                   wrap_tqdms = True, print_errors = True,\n",
    "                   best_model_file = best_model_file, parameters_file = parameters_file, grads_file = grads_file,\n",
    "                   train_errors_file = train_errors_file, test_errors_file = test_errors_file)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parameters_BN = []\n",
    "grads_BN = []\n",
    "for ind in range(4):\n",
    "    root = '../Result/VGG BN ' + str(lr[ind])\n",
    "    parameters_file = os.path.join(root, 'parameters.pt')\n",
    "    grads_file = os.path.join(root, 'grads.pt')\n",
    "\n",
    "    parameters_BN.append(torch.load(parameters_file, map_location = device))\n",
    "    grads_BN.append(torch.load(grads_file, map_location = device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min_curve, max_curve = grad_pred(grads_original)\n",
    "plt.fill_between(range(len(min_curve)), min_curve, max_curve, alpha = 0.75)\n",
    "\n",
    "min_curve, max_curve = grad_pred(grads_BN)\n",
    "plt.fill_between(range(len(min_curve)), min_curve, max_curve, alpha = 0.75)\n",
    "\n",
    "plt.ylim(0, 5)\n",
    "plt.legend(['VGG without BN', 'VGG with BN'])\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('gradient distance')\n",
    "plt.title('gradient predictiveness')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_curve1 = beta_smooth(parameters_original, grads_original)\n",
    "plt.plot(max_curve1, alpha = 0.5)\n",
    "\n",
    "max_curve2 = beta_smooth(parameters_BN, grads_BN)\n",
    "plt.plot(max_curve2, alpha = 0.5)\n",
    "\n",
    "plt.legend(['VGG without BN', 'VGG with BN'])\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('beta')\n",
    "plt.title('beta smoothness')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}